{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug torchrun_main_hook.py",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/torchrun_main_hook.py",
            "args": [
                "--model_config", "configs/llama_60m.json",
                "--seed", "42",
                "--lr", "0.01",
                "--rank", "128",
                "--lora_alpha", "0.4",
                "--update_proj_gap", "100",
                "--batch_size", "512",
                "--total_batch_size", "512",
                "--num_training_steps", "10000",
                "--warmup_steps", "1000",
                "--eval_every", "1000",
                "--save_every", "1000",
                "--dtype", "bfloat16",
                "--optimizer", "adamw",
                "--use_loqt", "True",
                "--proj_gap_progression", "exponential",
                "--increment_size", "1.2",
                "--save_original_model", "True",
                "--name", "60m_LoQT"
            ],
            "console": "integratedTerminal",
            "env": {
                "PYTHONPATH": "${workspaceFolder}"
            },
            "pythonPath": "${command:python.interpreterPath}",
            "cwd": "${workspaceFolder}",
            "preLaunchTask": "Run p1gpush and activate loqt"
        }
    ],
    "tasks": {
        "version": "2.0.0",
        "tasks": [
            {
                "label": "Run p1gpush and activate loqt",
                "type": "shell",
                "command": "p1gpush && conda activate loqt && exec ${command:python.interpreterPath} ${file}",
                "problemMatcher": [],
                "options": {
                    "shell": {
                        "executable": "/bin/bash",
                        "args": ["-l", "-c"]
                    }
                }
            }
        ]
    }
}