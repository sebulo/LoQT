{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug GSM8K",
            "type": "python",
            "request": "launch",
            "program": "${workspaceFolder}/run_GSM8K.py",
            "console": "integratedTerminal",
            "env": {
                "CUDA_VISIBLE_DEVICES": "1"
            },
            "args": [
                // "--model_name_or_path", "meta-llama/Llama-2-7b-hf",
                "--model_name_or_path", "EleutherAI/gpt-neo-1.3B",
                "--task_name", "gsm8k",
                "--num_train_epochs", "20",
                "--seed", "9876",
                "--lora_r", "32",
                "--lora_alpha", "2",
                "--update_proj_gap", "2400",
                "--bnb_4bit_quant_type", "nf4",
                "--quantize_w", "4bit",
                "--quantize_projection_matrix", "4bit",
                "--compensate_quant_error_iterations", "5",
                "--max_length", "256",
                "--pad_to_max_length",
                "--per_device_train_batch_size", "32",
                "--learning_rate", "8e-5",
                "--output_dir", "checkpoints",
                "--use_loqt", "true",
                "--single_gpu",
                "--with_tracking",
                "--report_to", "wandb",
                "--hub_token", "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"
            ]
        }
    ]
}